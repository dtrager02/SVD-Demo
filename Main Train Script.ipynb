{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SWillzs9nXYT"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1ucSJ1lWnXYW"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import AutoRecRecommender,AutoRecDataPrep2\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn import preprocessing\n",
        "from time import perf_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.ones(10).reshape((5,2))\n",
        "a[torch.tensor([1,2,3,3,3,3])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
            "         114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
            "         128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
            "         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
            "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
            "         170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
            "         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
            "         198, 199],\n",
            "        [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
            "         114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
            "         128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
            "         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
            "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
            "         170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
            "         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
            "         198, 199],\n",
            "        [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
            "         114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
            "         128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
            "         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
            "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
            "         170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
            "         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
            "         198, 199]]) tensor([[200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
            "         214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
            "         228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
            "         242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255,\n",
            "         256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
            "         270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
            "         284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
            "         298, 299],\n",
            "        [200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
            "         214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
            "         228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
            "         242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255,\n",
            "         256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
            "         270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
            "         284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
            "         298, 299],\n",
            "        [200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
            "         214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
            "         228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
            "         242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255,\n",
            "         256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
            "         270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
            "         284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
            "         298, 299]])\n",
            "4604.1599998716265\n"
          ]
        }
      ],
      "source": [
        "start = perf_counter()\n",
        "a = torch.arange(20000).reshape((200,100))\n",
        "print(a[[1,1,1]],a[[2,2,2]])\n",
        "torch.sum(a[list(range(150))]*(a[list(range(50,200))]),dim=1)\n",
        "print((perf_counter()-start)*800000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F5D3-XogOMur"
      },
      "outputs": [],
      "source": [
        "def get_time_array(data:pd.DataFrame):\n",
        "    groups = data.loc[:,[\"timestamp\",\"userId\"]].groupby(\"userId\")\n",
        "    print(\"Done grouping\")\n",
        "    groupmins = groups[\"timestamp\"].apply(pd.Series.min)\n",
        "    times = data.loc[:,[\"timestamp\"]].to_numpy(dtype=np.float32).reshape((-1,1))\n",
        "    print(\"Done finding min\",len(groupmins))\n",
        "    for name in groups.indices.keys():\n",
        "        # times[groups.indices[name]]= preprocessing.normalize([times[groups.indices[name]]])\n",
        "        min_max_scaler = preprocessing.MinMaxScaler()\n",
        "        times[groups.indices[name]] = min_max_scaler.fit_transform(times[groups.indices[name]])\n",
        "    data.loc[:,[\"timestamp\"]] = pd.Series(times.flatten())\n",
        "    # print(\"------------------\")\n",
        "    # print(data.groupby(\"userId\").min([\"timestamp\"]))\n",
        "    # print(\"----------------------\")\n",
        "    # print(data.groupby(\"userId\").max([\"timestamp\"]))\n",
        "    # print(\"----------------------\")\n",
        "    # print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q-uEZi_3nXYY",
        "outputId": "2cdcc750-fb86-4e3d-81c3-ed62a9a9d258"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>anime_id</th>\n",
              "      <th>score</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>126070</td>\n",
              "      <td>241</td>\n",
              "      <td>6</td>\n",
              "      <td>1293559897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>126070</td>\n",
              "      <td>650</td>\n",
              "      <td>8</td>\n",
              "      <td>1293560393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>126070</td>\n",
              "      <td>8074</td>\n",
              "      <td>9</td>\n",
              "      <td>1293560058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>126070</td>\n",
              "      <td>142</td>\n",
              "      <td>6</td>\n",
              "      <td>1294080780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>126070</td>\n",
              "      <td>252</td>\n",
              "      <td>10</td>\n",
              "      <td>1293559649</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   username  anime_id  score   timestamp\n",
              "0    126070       241      6  1293559897\n",
              "1    126070       650      8  1293560393\n",
              "2    126070      8074      9  1293560058\n",
              "3    126070       142      6  1294080780\n",
              "4    126070       252     10  1293559649"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = pd.read_feather(r\"cleaned_final_data.feather\")\n",
        "# a = pd.read_csv(r\"/content/NCF/ratings.csv\")\n",
        "a.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_1H_nsvAOgn",
        "outputId": "f167057e-34cb-4235-89f7-fe0a3c33656d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "username     int32\n",
            "anime_id     int32\n",
            "score         int8\n",
            "timestamp    int32\n",
            "dtype: object\n",
            "(57233503, 4)\n"
          ]
        }
      ],
      "source": [
        "print(a.dtypes)\n",
        "print(a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IVw0bxHd6E5F"
      },
      "outputs": [],
      "source": [
        "# a.drop(columns=[\"timestamp\"],inplace=True)\n",
        "a = a.to_numpy().astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([    126070,        241,          6, 1293559897])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEmevCxsoJBm",
        "outputId": "6e6e1835-fc34-4425-8948-6ce4e3059eb0"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available(): \n",
        "  print(\"we have cuda!\")\n",
        "  device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WRP2jcfUnXYa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Times stats 1660972384 0\n",
            "Rescaled item numbers\n",
            "Made sparse matrix\n"
          ]
        }
      ],
      "source": [
        "train = AutoRecDataPrep2.MovieLensTrainDataloader2(data=a,batch_size=2048)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz3bhknKsH0Z",
        "outputId": "b8516979-70b6-4c31-a8f6-da5730d88a00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.sparse_ratings2.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([593067, 3494])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.sparse_ratings2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUnz06H1nXYb",
        "outputId": "13710840-35c2-4bcb-ae62-b1edadd5ad75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AutoRec()"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = AutoRecRecommender.AutoRec(train.n_users, train.n_items,epochs= 30, hidden_size= 40)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "SEcV-IU8owGl"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0jO0dI00eu1r",
        "outputId": "06b6b171-a3f8-482d-cf4a-4024cb4cbba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions: N(3.852795362472534,2.367318868637085)\n",
            "Labels: N(3.8567678928375244,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 2.464524984359741; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n",
            "Predictions: N(3.857240676879883,1.1938449144363403)\n",
            "Labels: N(3.8567676544189453,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 1.3425321578979492; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n",
            "Predictions: N(3.8579485416412354,0.9588192701339722)\n",
            "Labels: N(3.856767416000366,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 1.122326135635376; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n",
            "Predictions: N(3.8569343090057373,0.8359776139259338)\n",
            "Labels: N(3.8567676544189453,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 1.0036529302597046; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n",
            "Predictions: N(3.8572065830230713,0.752622663974762)\n",
            "Labels: N(3.8567676544189453,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 0.9196706414222717; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n",
            "Predictions: N(3.8564507961273193,0.6907868981361389)\n",
            "Labels: N(3.8567676544189453,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 0.8540536761283875; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n",
            "Predictions: N(3.857603073120117,0.6433999538421631)\n",
            "Labels: N(3.8567676544189453,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 0.8008888363838196; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n",
            "Predictions: N(3.856421709060669,0.6073315739631653)\n",
            "Labels: N(3.8567676544189453,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 0.7573497891426086; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n",
            "Predictions: N(3.8568339347839355,0.5802668929100037)\n",
            "Labels: N(3.8567678928375244,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 0.7217514514923096; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n",
            "Predictions: N(3.8571670055389404,0.5604872107505798)\n",
            "Labels: N(3.8567676544189453,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 0.6929088830947876; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n",
            "Predictions: N(3.856764793395996,0.5470077395439148)\n",
            "Labels: N(3.8567676544189453,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 0.669815719127655; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n",
            "Predictions: N(3.8569374084472656,0.5380371809005737)\n",
            "Labels: N(3.8567676544189453,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 0.6516173481941223; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n",
            "Predictions: N(3.856843948364258,0.5327951312065125)\n",
            "Labels: N(3.8567678928375244,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 0.6374959349632263; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n",
            "Predictions: N(3.8567183017730713,0.5300886631011963)\n",
            "Labels: N(3.8567676544189453,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 0.6267215013504028; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n",
            "Predictions: N(3.8566226959228516,0.5288578271865845)\n",
            "Labels: N(3.8567676544189453,0.8026875257492065)\n",
            "-----------------------------------------------\n",
            "Current Train RMSE: 0.6186376214027405; Current Test RMSE: 1.0 Best Test RMSE: 1.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRW9QDre0DAT"
      },
      "outputs": [],
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "with profile(activities=[ProfilerActivity.CPU,ProfilerActivity.CUDA]) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "        model.fit(train)\n",
        "        # for input in iter(train):\n",
        "        #   pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pkyeqBX1HgU"
      },
      "outputs": [],
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI08uazw6IkD",
        "outputId": "38e4900e-9971-40f6-818e-c10c353d8e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "897845 4315\n",
            "Predictions: N(3.0860843658447266,0.7042092680931091)\n",
            "Labels: N(3.621346950531006,0.8693665862083435)\n",
            "Test RMSE: 0.9915255904197693\n"
          ]
        }
      ],
      "source": [
        "test = AutoRecTestDataPrep.MovieLensTestDataloader(train_data,test_data,batch_size=4096)\n",
        "print(test.n_users,test.n_items)\n",
        "model.eval()\n",
        "model.evaluate(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK5pMDp56Ddi"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"movielense_model.torch\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Train Script.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2a4fb80cb3c171773cd027240bb470c91e78114f9d815845cf91c954721f781f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
